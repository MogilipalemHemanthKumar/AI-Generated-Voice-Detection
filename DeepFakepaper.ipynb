{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qLgcmIScKe43"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, BatchNormalization, Bidirectional, LSTM\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1p1ueKnuK8x5",
        "outputId": "3f0287f7-59ac-45fb-c3ad-86beb3ae0aea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-q-9aYQ5LAF0"
      },
      "outputs": [],
      "source": [
        "# Load the dataset\n",
        "csv_output_path = 'drive/MyDrive/KAGGLE/audios.csv'\n",
        "dataset = pd.read_csv(csv_output_path)\n",
        "\n",
        "# Encode the labels\n",
        "label_encoder = LabelEncoder()\n",
        "dataset['LABEL'] = label_encoder.fit_transform(dataset['LABEL'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MDac3Bi5MjZ1"
      },
      "outputs": [],
      "source": [
        "# Split the dataset into features (X) and labels (y)\n",
        "X = dataset.iloc[:, :-2].values  # Exclude 'origin_sample' and 'LABEL'\n",
        "y = dataset['LABEL'].values\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qrvwEnaeMnf8"
      },
      "outputs": [],
      "source": [
        "# Scale the features\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train.reshape(X_train.shape[0], -1))\n",
        "X_test_scaled = scaler.transform(X_test.reshape(X_test.shape[0], -1))\n",
        "X_train_scaled = X_train_scaled.reshape(X_train.shape)\n",
        "X_test_scaled = X_test_scaled.reshape(X_test.shape)\n",
        "\n",
        "# Reshape the features to match the input shape expected by an RNN\n",
        "X_train_scaled = X_train_scaled.reshape(X_train_scaled.shape[0], X_train_scaled.shape[1], 1)\n",
        "X_test_scaled = X_test_scaled.reshape(X_test_scaled.shape[0], X_test_scaled.shape[1], 1)\n",
        "\n",
        "#X_train_scaled = np.expand_dims(X_train_scaled,axis=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOWTbm4xHh7a",
        "outputId": "b6473e6a-76ca-4b4f-f79b-a57b7515946c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(79624, 26)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AbGi6kkjMx0P"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Conv1D(filters=256, kernel_size=10, input_shape=(X_train.shape[1], 1),strides=5))\n",
        "model.add(BatchNormalization())  # Batch Normalization layer\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Conv1D(filters=256, kernel_size=8, strides=4,padding='same'))\n",
        "model.add(BatchNormalization())  # Batch Normalization layer\n",
        "\n",
        "model.add(Conv1D(filters=256, kernel_size=4, strides=2,padding='same'))\n",
        "\n",
        "model.add(Conv1D(filters=256, kernel_size=4, strides=2, padding='same'))\n",
        "model.add(Bidirectional(LSTM(units=512, return_sequences=True)))\n",
        "\n",
        "# Add Flatten layer to flatten the output before dense layers\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, input_dim=512, activation='relu'))\n",
        "model.add(Dense(1, input_dim=256, activation='sigmoid'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9s_tJfR6SBQX",
        "outputId": "12807066-a38b-4575-a35d-e92b326b5c0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d (Conv1D)             (None, 4, 256)            2816      \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 4, 256)            1024      \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1  (None, 2, 256)            0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 1, 256)            524544    \n",
            "                                                                 \n",
            " batch_normalization_1 (Bat  (None, 1, 256)            1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv1d_2 (Conv1D)           (None, 1, 256)            262400    \n",
            "                                                                 \n",
            " conv1d_3 (Conv1D)           (None, 1, 256)            262400    \n",
            "                                                                 \n",
            " bidirectional (Bidirection  (None, 1, 1024)           3149824   \n",
            " al)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1024)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               262400    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4466689 (17.04 MB)\n",
            "Trainable params: 4465665 (17.04 MB)\n",
            "Non-trainable params: 1024 (4.00 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S-eb_XTGU-E2"
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=1e-4), loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KYFTlwyjVQme"
      },
      "outputs": [],
      "source": [
        "# Define k-fold cross-validation\n",
        "kf = KFold(n_splits=2, shuffle=True, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dd4NEVtdVlmG",
        "outputId": "6d136652-4f25-45dc-c463-f59cd0bf54df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1245/1245 [==============================] - 157s 126ms/step - loss: 0.1792 - accuracy: 0.9274 - val_loss: 0.2222 - val_accuracy: 0.9160\n",
            "Epoch 2/10\n",
            "1245/1245 [==============================] - 164s 132ms/step - loss: 0.1735 - accuracy: 0.9290 - val_loss: 0.1840 - val_accuracy: 0.9266\n",
            "Epoch 3/10\n",
            "1245/1245 [==============================] - 166s 133ms/step - loss: 0.1691 - accuracy: 0.9317 - val_loss: 0.1913 - val_accuracy: 0.9222\n",
            "Epoch 4/10\n",
            "1245/1245 [==============================] - 164s 131ms/step - loss: 0.1633 - accuracy: 0.9338 - val_loss: 0.1858 - val_accuracy: 0.9247\n",
            "Epoch 5/10\n",
            "1245/1245 [==============================] - 164s 132ms/step - loss: 0.1600 - accuracy: 0.9346 - val_loss: 0.1757 - val_accuracy: 0.9298\n",
            "Epoch 6/10\n",
            "1245/1245 [==============================] - 164s 132ms/step - loss: 0.1546 - accuracy: 0.9362 - val_loss: 0.2021 - val_accuracy: 0.9233\n",
            "Epoch 7/10\n",
            "1245/1245 [==============================] - 165s 132ms/step - loss: 0.1504 - accuracy: 0.9384 - val_loss: 0.1817 - val_accuracy: 0.9243\n",
            "Epoch 8/10\n",
            "1245/1245 [==============================] - 157s 126ms/step - loss: 0.1473 - accuracy: 0.9405 - val_loss: 0.1705 - val_accuracy: 0.9314\n",
            "Epoch 9/10\n",
            "1245/1245 [==============================] - 164s 132ms/step - loss: 0.1430 - accuracy: 0.9414 - val_loss: 0.1647 - val_accuracy: 0.9314\n",
            "Epoch 10/10\n",
            "1245/1245 [==============================] - 163s 131ms/step - loss: 0.1393 - accuracy: 0.9426 - val_loss: 0.1693 - val_accuracy: 0.9300\n",
            "623/623 [==============================] - 10s 14ms/step\n",
            "Accuracy on test set: 0.9305736963729528\n",
            "Epoch 1/10\n",
            "1245/1245 [==============================] - 157s 126ms/step - loss: 0.1684 - accuracy: 0.9316 - val_loss: 0.1355 - val_accuracy: 0.9440\n",
            "Epoch 2/10\n",
            "1245/1245 [==============================] - 156s 126ms/step - loss: 0.1535 - accuracy: 0.9364 - val_loss: 0.1341 - val_accuracy: 0.9459\n",
            "Epoch 3/10\n",
            "1245/1245 [==============================] - 157s 126ms/step - loss: 0.1488 - accuracy: 0.9390 - val_loss: 0.1663 - val_accuracy: 0.9319\n",
            "Epoch 4/10\n",
            "1245/1245 [==============================] - 164s 132ms/step - loss: 0.1411 - accuracy: 0.9422 - val_loss: 0.1862 - val_accuracy: 0.9204\n",
            "Epoch 5/10\n",
            "1245/1245 [==============================] - 165s 133ms/step - loss: 0.1345 - accuracy: 0.9447 - val_loss: 0.1419 - val_accuracy: 0.9424\n",
            "Epoch 6/10\n",
            "1245/1245 [==============================] - 160s 128ms/step - loss: 0.1293 - accuracy: 0.9459 - val_loss: 0.1491 - val_accuracy: 0.9420\n",
            "Epoch 7/10\n",
            "1245/1245 [==============================] - 166s 133ms/step - loss: 0.1248 - accuracy: 0.9486 - val_loss: 0.1457 - val_accuracy: 0.9436\n",
            "Epoch 8/10\n",
            "1245/1245 [==============================] - 165s 133ms/step - loss: 0.1212 - accuracy: 0.9494 - val_loss: 0.1443 - val_accuracy: 0.9402\n",
            "Epoch 9/10\n",
            "1245/1245 [==============================] - 156s 125ms/step - loss: 0.1130 - accuracy: 0.9532 - val_loss: 0.1390 - val_accuracy: 0.9456\n",
            "Epoch 10/10\n",
            "1245/1245 [==============================] - 155s 125ms/step - loss: 0.1099 - accuracy: 0.9548 - val_loss: 0.1393 - val_accuracy: 0.9435\n",
            "623/623 [==============================] - 8s 13ms/step\n",
            "Accuracy on test set: 0.9405204460966543\n"
          ]
        }
      ],
      "source": [
        "# Store accuracies in a list\n",
        "accuracies = []\n",
        "# Perform k-fold cross-validation\n",
        "for train_index, val_index in kf.split(X_train_scaled):\n",
        "    X_train_fold, X_val_fold = X_train_scaled[train_index], X_train_scaled[val_index]\n",
        "    y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
        "\n",
        "    # Train the model on the current fold\n",
        "    model.fit(X_train_fold, y_train_fold, epochs=10, batch_size=32, validation_data=(X_val_fold, y_val_fold))\n",
        "\n",
        "    # Evaluate the model on the test set\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "    y_pred_binary = np.round(y_pred)\n",
        "    accuracy = accuracy_score(y_test, y_pred_binary)\n",
        "\n",
        "    accuracies.append(accuracy)\n",
        "\n",
        "    print(f'Accuracy on test set: {accuracy}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9sVm6wWlVqLY",
        "outputId": "5840c3f8-425b-41a0-b652-10f8ba5a0a87"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Accuracy: 0.9429317793630061\n"
          ]
        }
      ],
      "source": [
        "# Calculate and print the average accuracy\n",
        "average_accuracy = np.mean(accuracies)\n",
        "print(f'Average Accuracy: {average_accuracy}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cp6GKmC6ppzr"
      },
      "outputs": [],
      "source": [
        "# Load the dataset\n",
        "csv_output_path = 'audioTest.csv'\n",
        "dataset = pd.read_csv(csv_output_path)\n",
        "\n",
        "# Encode the labels\n",
        "label_encoder = LabelEncoder()\n",
        "dataset['LABEL'] = label_encoder.fit_transform(dataset['LABEL'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cXnP66kCIjxp"
      },
      "outputs": [],
      "source": [
        "# Split the dataset into features (X) and labels (y)\n",
        "X_test = dataset.iloc[:, :-2].values  # Exclude 'origin_sample' and 'LABEL'\n",
        "y_test = dataset['LABEL'].values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "glUbW_DZIs4p"
      },
      "outputs": [],
      "source": [
        "X_test_scaled = scaler.transform(X_test.reshape(X_test.shape[0], -1))\n",
        "X_test_scaled = X_test_scaled.reshape(X_test.shape)\n",
        "\n",
        "# Reshape the features to match the input shape expected by an RNN\n",
        "X_test_scaled = X_test_scaled.reshape(X_test_scaled.shape[0], X_test_scaled.shape[1], 1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RrFaI-H1JBTF",
        "outputId": "1a6179be-276b-4804-eb91-d02ca86b8913"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 0s 35ms/step\n",
            "Accuracy on test set: 0.5555555555555556\n"
          ]
        }
      ],
      "source": [
        "y_pred = model.predict(X_test_scaled)\n",
        "y_pred_binary = np.round(y_pred)\n",
        "accuracy = accuracy_score(y_test, y_pred_binary)\n",
        "\n",
        "print(f'Accuracy on test set: {accuracy}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VNsPPVu4p4PH"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "pickle_out = open(\"deepFake.pkl\",\"wb\")\n",
        "pickle.dump(model, pickle_out)\n",
        "pickle_out.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4vS9cyjHvxAP"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}